{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraper:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "\n",
    "    def extract_article_text(self):\n",
    "        response = requests.get(self.url)\n",
    "        html_content = response.content\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        article_text = soup.get_text()\n",
    "        return article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 followers in 2 weeks!. Nothing much, just my story. | by Richard Warepam | New Writers Welcome | Medium100 followers in 2 weeks!Nothing much, just my story.Richard Warepam¬∑FollowPublished inNew Writers Welcome¬∑3 min read¬∑Jan 20, 2022--54ListenSharePhoto by Andrea Piacquadio from PexelsHey, I am Richard. I gained 100 followers in two weeks, but I can‚Äôt even participate in the Medium Partner Program because I am from India. To be honest, I had never heard of this platform before. On January 2, 2022, I discovered this platform.Jan. 1, 2022:Happy New Year! I considered doing something different besides my developer‚Äôs work. So, I created a basic blogging website and began blogging! It was a lot of fun! It was well-received by my friends who read it.My Website:Home | WRS CreaDevs Warepam | Richard's WebsiteWRS CreaDevs is created by Richard Warepam. It is a personal website of Richard Warepam. Richard Warepam is a Software‚Ä¶richardwarepam.techJan. 2, 2022:While scrolling through my Facebook feed, an advertisement for Medium with a very nice article appeared. I read that article and a few others before being asked to join as a member in order to read more. So, I joined instantly. Then, I fell head over heels in love with this platform.Jan. 3, 2022:I came to know that this platform pays the writers monthly after joining a partner program. I got more interested but later, found out it is still yet not eligible for Indians. Honestly, I got a little disappointed.Jan. 4, 2022:Thought why not share my knowledge and thoughts here as well? So I published two stories, and there was no engagement for a week!Jan. 11, 2022:After only writing stories for my website and Medium every morning for 7 days! When I open my Medium account, I see a lot of notifications and notice that the 2nd story I posted, is kinda going viral because a lot of people read it and even followed me!Here is the story:How to Become a Blockchain Developer?Want to read more of my content, visit: https://richardwarepam.tech/blogs/blog.cryptostars.isJan. 18, 2022:After 7 days of gradually increasing engagement, there were now around 300+ views per day. On this day, I saw a higher level of engagement! It has even received 500+ views, and the number of followers is growing. Later, I discovered that, of the total stories I posted, one more story has also kinda gone viral and is receiving a lot of engagement!The Story:5 Layers of SoftwareEvery Developer Should Have Cakemedium.comJan. 20, 2022:I‚Äôve posted 14 stories in two weeks and have 100 followers! And I still have no idea how the algorithm works! I‚Äôm still learning about the features of this platform.Yeah, I‚Äôm not eligible for the partner program, and I‚Äôm not making any money from my stories, but I‚Äôm glad I‚Äôm slowly building a community where I can freely share my knowledge and thoughts.Thank you to everyone who has followed me and found my articles useful! I will continue to post articles because I am enjoying it!If you are a new reader of my articles and if you like my writings. I write about some of my personal experiences and all about BRAINS(Blockchain, Robotics, AI, and Network Security). Please make sure you follow me on Medium. You can also check out more content on my website: https://richardwarepam.tech/blogs/Richard Warepam, Software Developer.100 Followers100 Followers On MediumMedium Partner ProgramMedium PartnershipNew Writers Welcome----54FollowWritten by Richard Warepam2.7K Followers¬∑Writer for New Writers WelcomeAI / ML & Data Engineer | Technical Blogger | For any ghostwriting gigs: richardwarepam16@gmail.comFollowMore from Richard Warepam and New Writers WelcomeRichard WarepaminDare To Be Better7 Books to Be the Top Data EngineerIn today‚Äôs data-driven world, data engineering plays a pivotal role in transforming raw data into actionable insights. Aspiring data‚Ä¶6 min read¬∑Jul 2--4Mike LewisinNew Writers WelcomeWhy Bother Giving 50 Claps When Only the First One Counts?Should we all start giving one clap?¬∑3 min read¬∑Aug 12--354Bikendra ThapainNew Writers WelcomeChanging someone‚Äôs opinion? Don‚Äôt persuadeWe think if we only provide one more justification, people would finally change. Sadly, such an approach doesn‚Äôt succeed.¬∑3 min read¬∑Sep 1--94Richard WarepaminDare To Be BetterData Modelling in DataWarehouse: The Ultimate GuideDefinition, Why we need it and Execution4 min read¬∑Apr 16--1See all from Richard WarepamSee all from New Writers WelcomeRecommended from MediumJonathan LethemBe Kind, Be Kind, Be KindHenry James, Mr. Rogers, and the Long Middle4 min read¬∑Sep 21--132Matt AldrichinùêÄùêà ùê¶ùê®ùêßùê§ùê¨.ùê¢ùê®We need professional writersA friend who works in tech law said something to me over the summer that I can‚Äôt quite shake. He said, ‚ÄúAI won‚Äôt take your job, a person‚Ä¶7 min read¬∑Sep 19--82ListsMedium Publications Accepting Story Submissions154 stories¬∑732 savesRenuka GavraniinBooks Are Our SuperpowerThe Book That Made Me Reflect On the Cruel History & Missed Opportunities of WomenNot another average book on feminism¬∑7 min read¬∑3 days ago--9Eric S BurdoninPurposeful LifeHow Self-Help Has Created More Work For YouSeeking to improve yourself has become a much bigger hassle than ever.¬∑9 min read¬∑Sep 19--17Neeramitra ReddyinBetter HumansThe Most Powerful Morning Routine I‚Äôve Found After 3+ Years of ExperimentingA realistic, science-based, customizable, and aggressively self-tested morning system¬∑18 min read¬∑Sep 19--65Zaki AhmedWhy won‚Äôt My Imposter Syndrome Go Away?A part of me whispers ‚ÄúI can‚Ä¶‚Äù, and then comes the other part of me yelling ‚ÄúCan You?‚Äù\n",
      "¬†That‚Äôs pretty much how I keep going back and forth‚Ä¶4 min read¬∑Sep 17--4See more recommendationsHelpStatusWritersBlogCareersPrivacyTermsAboutText to speechTeams\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    article_url = \"https://medium.com/new-writers-welcome/100-followers-in-2-weeks-8e814c8d5c98\"\n",
    "    scraper = WebScraper(article_url)\n",
    "    scraped_text = scraper.extract_article_text()\n",
    "    print(scraped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 60]\n",
      "[nltk_data]     Operation timed out>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self,nltk_stopwords):\n",
    "        self.nltk_stopwords = nltk_stopwords\n",
    "\n",
    "    def tokenize_and_clean(self, text):\n",
    "        words = text.split()\n",
    "        filtered_words = [word.lower() for word in words if word.isalpha() and word.lower() not in self.nltk_stopwords]\n",
    "        return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETLPipeline:\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "        self.nltk_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    def run(self):\n",
    "        scraper = WebScraper(self.url)\n",
    "        article_text = scraper.extract_article_text()\n",
    "\n",
    "        processor = TextProcessor(self.nltk_stopwords)\n",
    "        filtered_words = processor.tokenize_and_clean(article_text)\n",
    "        word_freq = Counter(filtered_words)\n",
    "        df = pd.DataFrame(word_freq.items(), columns=[\"Words\", \"Frequencies\"])\n",
    "        df = df.sort_values(by=\"Frequencies\", ascending=False)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/macbookpro/nltk_data'\n    - '/Users/macbookpro/anaconda3/nltk_data'\n    - '/Users/macbookpro/anaconda3/share/nltk_data'\n    - '/Users/macbookpro/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/nltk/corpus/util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mzip_name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     85\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/Users/macbookpro/nltk_data'\n    - '/Users/macbookpro/anaconda3/nltk_data'\n    - '/Users/macbookpro/anaconda3/share/nltk_data'\n    - '/Users/macbookpro/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/BOOTCAMP/CASE-STUDIES/webData_ETLPipeline/etl.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/BOOTCAMP/CASE-STUDIES/webData_ETLPipeline/etl.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/BOOTCAMP/CASE-STUDIES/webData_ETLPipeline/etl.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     article_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://medium.com/new-writers-welcome/100-followers-in-2-weeks-8e814c8d5c98\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Volumes/BOOTCAMP/CASE-STUDIES/webData_ETLPipeline/etl.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     pipeline \u001b[39m=\u001b[39m ETLPipeline(article_url)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/BOOTCAMP/CASE-STUDIES/webData_ETLPipeline/etl.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     result \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mrun()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/BOOTCAMP/CASE-STUDIES/webData_ETLPipeline/etl.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(result\u001b[39m.\u001b[39mhead())\n",
      "\u001b[1;32m/Volumes/BOOTCAMP/CASE-STUDIES/webData_ETLPipeline/etl.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/BOOTCAMP/CASE-STUDIES/webData_ETLPipeline/etl.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,url):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/BOOTCAMP/CASE-STUDIES/webData_ETLPipeline/etl.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl \u001b[39m=\u001b[39m url\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Volumes/BOOTCAMP/CASE-STUDIES/webData_ETLPipeline/etl.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnltk_stopwords \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39;49mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/nltk/corpus/util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLazyCorpusLoader object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load()\n\u001b[1;32m    122\u001b[0m \u001b[39m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m# __class__ to something new:\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/nltk/corpus/util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfind(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubdir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mzip_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     88\u001b[0m \u001b[39m# Load the corpus.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__reader_cls(root, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/nltk/corpus/util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     82\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/macbookpro/nltk_data'\n    - '/Users/macbookpro/anaconda3/nltk_data'\n    - '/Users/macbookpro/anaconda3/share/nltk_data'\n    - '/Users/macbookpro/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    article_url = \"https://medium.com/new-writers-welcome/100-followers-in-2-weeks-8e814c8d5c98\"\n",
    "    pipeline = ETLPipeline(article_url)\n",
    "    result = pipeline.run()\n",
    "    print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
